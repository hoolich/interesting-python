{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据挖掘、机器学习算法实习生需求分析  \n",
    "\n",
    "  \n",
    "  接上篇文章的“实习僧网站”数据爬取，这篇文章主要对“实习僧网站”招聘数据挖掘、机器学习的实习岗位信息进行分析。数据主要来自“数据挖掘”、“机器学习”和“算法”这3个关键词下的数据。爬下来的原始数据还比较脏，本文使用pandas进行数据处理和分析，结合seaborn和pyecharts包进行数据可视化。Python运行版本为3.6.3。\n",
    "\n",
    "### 分析目标\n",
    "1. 由于小E想要找的实习公司是机器学习算法相关的工作，所以只对“数据挖掘”、“机器学习”、“算法”这三个关键字进行了爬取；\n",
    "2. 因此，分析目标就是国内公司对机器学习算法实习生的需求状况（仅基于实习僧网站），以及公司相关的分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyecharts\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "from pylab import mpl\n",
    "mpl.rcParams['font.sans-serif'] = ['SimHei']  #解决seaborn中文字体显示问题\n",
    "plt.rc('figure', figsize=(10, 10))  #把plt默认的图片size调大一点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 数据导入\n",
    "- 把通过“数据挖掘”、“机器学习”和“算法”这3个关键词爬取到的3个csv文件数据导入为pandas DataFrame，再把他们concat起来\n",
    "- 把ignore_index设置成True让其可以重新索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dm = pd.read_csv(\"datamining.csv\")\n",
    "data_ml = pd.read_csv(\"machinelearning.csv\")\n",
    "data_al = pd.read_csv(\"mlalgorithm.csv\")\n",
    "data = pd.concat([data_dm, data_ml, data_al], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 数据基本信息和基本处理\n",
    "- 随机抽取3个数据样本看数据是否导入正确\n",
    "- 查看数据基本信息，看数据的行列数、数据类型是否正确、是否有重复数据，以及首先对重复数据进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auth_capital</th>\n",
       "      <th>city</th>\n",
       "      <th>com_class</th>\n",
       "      <th>com_fullname</th>\n",
       "      <th>com_id</th>\n",
       "      <th>com_intro</th>\n",
       "      <th>com_links</th>\n",
       "      <th>com_location</th>\n",
       "      <th>com_logo</th>\n",
       "      <th>com_name</th>\n",
       "      <th>...</th>\n",
       "      <th>job_deadline</th>\n",
       "      <th>job_detail</th>\n",
       "      <th>job_links</th>\n",
       "      <th>job_title</th>\n",
       "      <th>num_employee</th>\n",
       "      <th>released_time</th>\n",
       "      <th>tag</th>\n",
       "      <th>time_span</th>\n",
       "      <th>update_time</th>\n",
       "      <th>wage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>注册资本：2000 万元人民币</td>\n",
       "      <td>杭州</td>\n",
       "      <td>公司类型：私营有限责任公司(自然人控股或私营性质企业控股)</td>\n",
       "      <td>杭州斯凯网络科技有限公司</td>\n",
       "      <td>注册号：330108000005379</td>\n",
       "      <td>人人尽享移动生活</td>\n",
       "      <td>https://www.shixiseng.com/com/com_5fdoz7rla1ro</td>\n",
       "      <td>杭州市西湖区紫荆花路2号联合大厦B座10F</td>\n",
       "      <td>https://sxsimg.xiaoyuanzhao.com/A1/73/A1C9CB89...</td>\n",
       "      <td>斯凯网络</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-04-14</td>\n",
       "      <td>['岗位职责', '、负责公司医疗及其他项目的现场数据开发工作；', '、负责用户需求的满足...</td>\n",
       "      <td>https://www.shixiseng.com/intern/inn_qmfyym6smqbj</td>\n",
       "      <td>数据开发工程师</td>\n",
       "      <td>500-2000人</td>\n",
       "      <td>2天前</td>\n",
       "      <td>数据挖掘</td>\n",
       "      <td>7个月</td>\n",
       "      <td>2018-03-19 09:34:25</td>\n",
       "      <td>100-148/天</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>注册资本：1000万人民币</td>\n",
       "      <td>上海漕河泾开发区</td>\n",
       "      <td>公司类型：有限责任公司</td>\n",
       "      <td>上海触宝信息技术有限公司</td>\n",
       "      <td>注册号：310104000513388</td>\n",
       "      <td>创新型的高科技企业</td>\n",
       "      <td>https://www.shixiseng.com/com/com_ucz9bab6omrk</td>\n",
       "      <td>深圳市南山区科技园科技路9号图道科技大厦</td>\n",
       "      <td>https://sxsimg.xiaoyuanzhao.com/EC/10/EC71FF14...</td>\n",
       "      <td>触宝</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>['岗位职责：', '1.负责自然语义理解的研发工作；', '2.负责相关语料库/知识库的采...</td>\n",
       "      <td>https://www.shixiseng.com/intern/inn_olm8lioz6itd</td>\n",
       "      <td>自然语言处理工程师</td>\n",
       "      <td>150-500人</td>\n",
       "      <td>5小时前</td>\n",
       "      <td>算法</td>\n",
       "      <td>6个月</td>\n",
       "      <td>2018-03-22 10:24:54</td>\n",
       "      <td>200-260/天</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>注册资本：500 万元人民币</td>\n",
       "      <td>杭州</td>\n",
       "      <td>公司类型：私营有限责任公司(自然人控股或私营性质企业控股)</td>\n",
       "      <td>杭州光珀智能科技有限公司</td>\n",
       "      <td>注册号：330106000408888</td>\n",
       "      <td>技术全球领先，团队来自浙大及海外核心人才</td>\n",
       "      <td>https://www.shixiseng.com/com/com_wfffyl8hfcji</td>\n",
       "      <td>杭州市石祥西路859号紫金创业园B座13楼</td>\n",
       "      <td>https://sxsimg.xiaoyuanzhao.com/62/9E/62BF03CA...</td>\n",
       "      <td>光珀</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>['毕业后可留任公司发展', '岗位职责：', '1、基于深度相机的图像预处理；', '2、...</td>\n",
       "      <td>https://www.shixiseng.com/intern/inn_hilvgcfjm0vs</td>\n",
       "      <td>图像算法工程师</td>\n",
       "      <td>50-150人</td>\n",
       "      <td>1周前</td>\n",
       "      <td>算法</td>\n",
       "      <td>15个月</td>\n",
       "      <td>2018-03-12 18:32:19</td>\n",
       "      <td>200-400/天</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        auth_capital      city                      com_class  com_fullname  \\\n",
       "111  注册资本：2000 万元人民币        杭州  公司类型：私营有限责任公司(自然人控股或私营性质企业控股)  杭州斯凯网络科技有限公司   \n",
       "391    注册资本：1000万人民币  上海漕河泾开发区                    公司类型：有限责任公司  上海触宝信息技术有限公司   \n",
       "810   注册资本：500 万元人民币        杭州  公司类型：私营有限责任公司(自然人控股或私营性质企业控股)  杭州光珀智能科技有限公司   \n",
       "\n",
       "                  com_id             com_intro  \\\n",
       "111  注册号：330108000005379              人人尽享移动生活   \n",
       "391  注册号：310104000513388             创新型的高科技企业   \n",
       "810  注册号：330106000408888  技术全球领先，团队来自浙大及海外核心人才   \n",
       "\n",
       "                                          com_links           com_location  \\\n",
       "111  https://www.shixiseng.com/com/com_5fdoz7rla1ro  杭州市西湖区紫荆花路2号联合大厦B座10F   \n",
       "391  https://www.shixiseng.com/com/com_ucz9bab6omrk   深圳市南山区科技园科技路9号图道科技大厦   \n",
       "810  https://www.shixiseng.com/com/com_wfffyl8hfcji  杭州市石祥西路859号紫金创业园B座13楼   \n",
       "\n",
       "                                              com_logo com_name  ...  \\\n",
       "111  https://sxsimg.xiaoyuanzhao.com/A1/73/A1C9CB89...     斯凯网络  ...   \n",
       "391  https://sxsimg.xiaoyuanzhao.com/EC/10/EC71FF14...       触宝  ...   \n",
       "810  https://sxsimg.xiaoyuanzhao.com/62/9E/62BF03CA...       光珀  ...   \n",
       "\n",
       "    job_deadline                                         job_detail  \\\n",
       "111   2018-04-14  ['岗位职责', '、负责公司医疗及其他项目的现场数据开发工作；', '、负责用户需求的满足...   \n",
       "391   2018-04-16  ['岗位职责：', '1.负责自然语义理解的研发工作；', '2.负责相关语料库/知识库的采...   \n",
       "810   2018-11-30  ['毕业后可留任公司发展', '岗位职责：', '1、基于深度相机的图像预处理；', '2、...   \n",
       "\n",
       "                                             job_links  job_title  \\\n",
       "111  https://www.shixiseng.com/intern/inn_qmfyym6smqbj    数据开发工程师   \n",
       "391  https://www.shixiseng.com/intern/inn_olm8lioz6itd  自然语言处理工程师   \n",
       "810  https://www.shixiseng.com/intern/inn_hilvgcfjm0vs    图像算法工程师   \n",
       "\n",
       "    num_employee released_time   tag time_span          update_time       wage  \n",
       "111    500-2000人           2天前  数据挖掘       7个月  2018-03-19 09:34:25  100-148/天  \n",
       "391     150-500人          5小时前    算法       6个月  2018-03-22 10:24:54  200-260/天  \n",
       "810      50-150人           1周前    算法      15个月  2018-03-12 18:32:19  200-400/天  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机抽取一个数据，看看这个数据样本所有特征的数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "auth_capital                                      注册资本：130.2083万人民币\n",
       "city                                                             上海\n",
       "com_class                                 公司类型：股份有限公司(台港澳与境内合资、未上市)\n",
       "com_fullname                                         纵目科技（上海）股份有限公司\n",
       "com_id                                            组织机构代码：06087276-7\n",
       "com_intro                               成为立足中国面向世界的从辅助驾驶到自动驾驶的技术引领者\n",
       "com_links            https://www.shixiseng.com/com/com_k0gejst3xf8x\n",
       "com_location                                北京市昌平区回龙观东大街腾讯总创空间B座535\n",
       "com_logo          https://sxsimg.xiaoyuanzhao.com/7B/C2/7B75BE25...\n",
       "com_name                                                       纵目科技\n",
       "com_website                               http://www.zongmutech.com\n",
       "com_welfare       ['发展潜力大', '活跃的工作环境', '团队体验', '棒棒的', '开放创新', '追...\n",
       "day_per_week                                                   4天/周\n",
       "detailed_intro    \\n纵目科技成立于2013年1月，总部位于上海浦东张江高科技园区，在北京及深圳分别设有研发分...\n",
       "est_date                                            成立日期：2013-01-10\n",
       "industry                                                       汽车电子\n",
       "job_academic                                                     硕士\n",
       "job_deadline                                             2018-04-30\n",
       "job_detail                                                      NaN\n",
       "job_links         https://www.shixiseng.com/intern/inn_44wj24z3ra6h\n",
       "job_title                                                   视觉算法工程师\n",
       "num_employee                                               150-500人\n",
       "released_time                                                   3天前\n",
       "tag                                                              算法\n",
       "time_span                                                       3个月\n",
       "update_time                                     2018-03-19 13:04:08\n",
       "wage                                                      200-400/天\n",
       "Name: 666, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[666]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取数据的基本信息，发现：\n",
    "1. 一共有978条记录，27列\n",
    "2. 某些列比如说“com_id”、“detailed_intro”、“est_date”等，具有些许缺失值\n",
    "3. 所有数据都被导入成了object类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 978 entries, 0 to 977\n",
      "Data columns (total 27 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   auth_capital    906 non-null    object\n",
      " 1   city            974 non-null    object\n",
      " 2   com_class       954 non-null    object\n",
      " 3   com_fullname    974 non-null    object\n",
      " 4   com_id          906 non-null    object\n",
      " 5   com_intro       974 non-null    object\n",
      " 6   com_links       978 non-null    object\n",
      " 7   com_location    978 non-null    object\n",
      " 8   com_logo        974 non-null    object\n",
      " 9   com_name        974 non-null    object\n",
      " 10  com_website     865 non-null    object\n",
      " 11  com_welfare     978 non-null    object\n",
      " 12  day_per_week    978 non-null    object\n",
      " 13  detailed_intro  912 non-null    object\n",
      " 14  est_date        906 non-null    object\n",
      " 15  industry        960 non-null    object\n",
      " 16  job_academic    978 non-null    object\n",
      " 17  job_deadline    978 non-null    object\n",
      " 18  job_detail      681 non-null    object\n",
      " 19  job_links       978 non-null    object\n",
      " 20  job_title       978 non-null    object\n",
      " 21  num_employee    972 non-null    object\n",
      " 22  released_time   978 non-null    object\n",
      " 23  tag             978 non-null    object\n",
      " 24  time_span       978 non-null    object\n",
      " 25  update_time     978 non-null    object\n",
      " 26  wage            978 non-null    object\n",
      "dtypes: object(27)\n",
      "memory usage: 206.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 由于数据是通过3个关键词搜索爬取的，难免会有一个职位对应多个关键词的情况，所以难免会有重复数据  \n",
    "- 这些重复数据对于我们的分析没有帮助，先drop掉，再看剩余数据情况\n",
    "- 由于“job_links”字段（工作详情链接）对数据可以起唯一标识作用，所以可以基于该字段去重\n",
    "- 发现数据剩余878行（说明刚好有100条重复数据）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(878, 27)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop_duplicates(subset='job_links', inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 数据处理\n",
    "由上可见：\n",
    "- com_fullname、com_name、job_academic、job_links、tag不需要处理\n",
    "- “auth_capital”（注册资本）、“day_per_week”（每周工作天数）、“num_employee”（公司规模）、“time_span”（实习月数）、“wage”（每天工资）等字段，都可以处理成数值型数据\n",
    "- “est_date”（公司成立日期）、“job_deadline”（截止时间）、“released_time”（发布时间）、“update_time”（更新时间）等字段，可以处理成datetime类型数据\n",
    "- “city”（城市）、“com_class”（公司类型）、“com_intro（公司简介）”、“job_title”（职位名称）等字段可以进一步处理\n",
    "- 类似于“com_logo”（公司logo）、“industry”（行业）等字段，可以视情况处理\n",
    "- com_id、com_links、com_location、com_website、com_welfare、detailed_intro、job_detail在本次分析中用不上，不处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 新建data_clean数据框\n",
    "- 新建data_clean数据框，数据处理在data_clean上进行\n",
    "- data_clean用以保存处理好的数据，原数据data用以保存原始数据记录\n",
    "- 把本次分析中用不上的字段先drop掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = data.drop(['com_id', 'com_links', 'com_location', 'com_website', \n",
    "                 'com_welfare', 'detailed_intro', 'job_detail'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 数值型数据处理\n",
    "包括“auth_capital”（注册资本）、“day_per_week”（每周工作天数）、“num_employee”（公司规模）、“time_span”（实习月数）、“wage”（每天工资）等字段  \n",
    "\n",
    "##### 3.2.1 “auth_capital”（注册资本）\n",
    "- 随机抽取“auth_capital”，发现该字段的格式基本为：“注册资本：（数字）万|万元（币种）”，有少许的格式为：“注册资本：（币种）（数字）万|万元”， 或者“注册资本：无”，或者该字段为缺失值\n",
    "- 币种有人民币、美元、欧元、港元（港币）等\n",
    "- 这里的处理思路是先把“注册资本：”清理掉，再把数值型数据提取出来，然后根据各币种的汇率，把注册资本转换为“万元人民币”单位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569                    NaN\n",
       "528      注册资本：1476.92万元人民币\n",
       "347          注册资本：1500万人民币\n",
       "84        注册资本：1000 万元 人民币\n",
       "865         注册资本：306 万元 美元\n",
       "417            注册资本：100 万元\n",
       "193          注册资本：2000万人民币\n",
       "67       注册资本：5884.804万人民币\n",
       "950         注册资本：4000万元人民币\n",
       "484         注册资本：100 万元 美元\n",
       "85             注册资本：480万美元\n",
       "426            注册资本：80万人民币\n",
       "672           注册资本：2105 万元\n",
       "424        注册资本：100 万元 人民币\n",
       "936       注册资本：87.2629万人民币\n",
       "823         注册资本：1230万元人民币\n",
       "70           注册资本：6000万人民币\n",
       "9           注册资本：3000万元人民币\n",
       "941    注册资本：14503.125万元人民币\n",
       "812           注册资本：1900 万元\n",
       "Name: auth_capital, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.auth_capital.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 先以“：”分割字符串，便可把“注册资本：”清理掉，保留数值和币种"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>注册资本</td>\n",
       "      <td>500万元人民币</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>注册资本</td>\n",
       "      <td>2000 万元人民币</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>注册资本</td>\n",
       "      <td>3000万</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>注册资本</td>\n",
       "      <td>1023.7388万人民币元</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>注册资本</td>\n",
       "      <td>560000万元人民币</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0               1\n",
       "508  注册资本        500万元人民币\n",
       "111  注册资本      2000 万元人民币\n",
       "696  注册资本           3000万\n",
       "648  注册资本  1023.7388万人民币元\n",
       "761  注册资本     560000万元人民币"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auth_capital = data['auth_capital'].str.split('：', expand = True)\n",
    "auth_capital.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 接着把数字提取出来， 转换为float型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>注册资本</td>\n",
       "      <td>36409.6355 万元 人民币</td>\n",
       "      <td>36409.6355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>注册资本</td>\n",
       "      <td>5000万人民币</td>\n",
       "      <td>5000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>注册资本</td>\n",
       "      <td>1190.476200万人民币</td>\n",
       "      <td>1190.4762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>注册资本</td>\n",
       "      <td>306 万元 美元</td>\n",
       "      <td>306.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>注册资本</td>\n",
       "      <td>1000 万元 人民币</td>\n",
       "      <td>1000.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0                  1         num\n",
       "359  注册资本  36409.6355 万元 人民币  36409.6355\n",
       "37   注册资本           5000万人民币   5000.0000\n",
       "199  注册资本    1190.476200万人民币   1190.4762\n",
       "849  注册资本          306 万元 美元    306.0000\n",
       "847  注册资本        1000 万元 人民币   1000.0000"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auth_capital['num'] = auth_capital[1].str.extract('([0-9.]+)', expand=False).astype('float')\n",
    "auth_capital.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 币种的描述比较乱，比如同是人民币，描述有“万人民币”、“万元人民币”、“万人民币元”、“万元 人民币”等\n",
    "- 先看看币种的描述都有哪些（以“万”字分割字符串，便可把数值和币种分开来）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['美元', '人民币', '元美元', nan, '元人民币', '人民币元', '元', None, '元 人民币', '',\n",
       "       '元 美元', '元港元（港币）', '港币', '香港元', '欧元', '元 港元（港币）'], dtype=object)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auth_capital[1].str.split('万', expand = True)[1].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 币种的描述有多种， 我们可以根据不同币种，在数值上乘以相应的汇率，转换为“万元人民币”单位\n",
    "- 为了过程更好理解，可以先新建一个“ex_rate”（汇率）列，保存对应的汇率，由于数据量不大，这里用pd.Series.apply(function)（当然也可以使用pd.DataFrame.apply(function)一步到位）\n",
    "- 港币、美元、欧元兑人民币的汇率分别为 0.80、6.29、7.73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>num</th>\n",
       "      <th>ex_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>注册资本</td>\n",
       "      <td>3215万美元</td>\n",
       "      <td>3215.0000</td>\n",
       "      <td>6.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>注册资本</td>\n",
       "      <td>5000万元人民币</td>\n",
       "      <td>5000.0000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>注册资本</td>\n",
       "      <td>524.8332 万元 美元</td>\n",
       "      <td>524.8332</td>\n",
       "      <td>6.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>注册资本</td>\n",
       "      <td>500万元人民币</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0               1        num  ex_rate\n",
       "421  注册资本         3215万美元  3215.0000     6.29\n",
       "250   NaN             NaN        NaN      NaN\n",
       "352  注册资本       5000万元人民币  5000.0000     1.00\n",
       "252  注册资本  524.8332 万元 美元   524.8332     6.29\n",
       "503  注册资本        500万元人民币   500.0000     1.00"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ex_rate(string):\n",
    "    if string == None:\n",
    "        return np.nan\n",
    "    if '人民币' in string:\n",
    "        return 1.00\n",
    "    elif '港' in string:\n",
    "        return 0.80\n",
    "    elif '美元' in string:\n",
    "        return 6.29\n",
    "    elif '欧元' in string:\n",
    "        return 7.73\n",
    "    elif '万' in string:\n",
    "        return 1.00\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "auth_capital['ex_rate'] = auth_capital[1].astype(str).apply(get_ex_rate)\n",
    "auth_capital.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 由'num'和'ex_rate'相乘便是转换为“万元人民币”的注册资本字段\n",
    "- 把干净的数据保存进data_clean中，方便之后分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    235875.0000\n",
       "1     27570.9972\n",
       "2       314.5000\n",
       "3     28430.8000\n",
       "4     28430.8000\n",
       "Name: auth_capital, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean['auth_capital'] = auth_capital['num'] * auth_capital['ex_rate']\n",
    "data_clean['auth_capital'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.2 “day_per_week”（每周工作天数）\n",
    "由下可见：\n",
    "- “day_per_week”字段没有缺失值，并且取值在“2-6天/周”之间\n",
    "- 可以采用直接赋值的方法处理该字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['4天/周', '5天/周', '3天/周', '2天/周', '6天/周'], dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.day_per_week.unique()#去重合并成数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.loc[data['day_per_week'] == '2天/周', 'day_per_week'] = 2\n",
    "data_clean.loc[data['day_per_week'] == '3天/周', 'day_per_week'] = 3\n",
    "data_clean.loc[data['day_per_week'] == '4天/周', 'day_per_week'] = 4\n",
    "data_clean.loc[data['day_per_week'] == '5天/周', 'day_per_week'] = 5\n",
    "data_clean.loc[data['day_per_week'] == '6天/周', 'day_per_week'] = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.3 “num_employee”（公司规模）\n",
    "- 同样，由于“num_employee”字段取值在['2000人以上', '500-2000人', nan, '50-150人', '15-50人', '150-500人', '少于15人', '5000人以上']，可以采用跟“day_per_week”字段一样的处理方法\n",
    "- '少于15人'、'15-50人'、'50-150人'都记为'小型企业','150-500人'、'500-2000人'记为'中型企业'，'2000人以上'、'5000人以上'记为大型企业"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2000人以上', '500-2000人', nan, '50-150人', '15-50人', '150-500人',\n",
       "       '少于15人', '5000人以上'], dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_employee.unique()#去重合并成数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.loc[data['num_employee'] == '少于15人', 'num_employee'] = '小型企业'\n",
    "data_clean.loc[data['num_employee'] == '15-50人', 'num_employee'] = '小型企业'\n",
    "data_clean.loc[data['num_employee'] == '50-150人', 'num_employee'] = '小型企业'\n",
    "data_clean.loc[data['num_employee'] == '150-500人', 'num_employee'] = '中型企业'\n",
    "data_clean.loc[data['num_employee'] == '500-2000人', 'num_employee'] = '中型企业'\n",
    "data_clean.loc[data['num_employee'] == '2000人以上', 'num_employee'] = '大型企业'\n",
    "data_clean.loc[data['num_employee'] == '5000人以上', 'num_employee'] = '大型企业'\n",
    "data_clean.loc[data['num_employee'].isna(), 'num_employee'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.4 “time_span”（实习月数）\n",
    "由下可知：\n",
    "- “time_span”字段没有缺失值，由“1-18个月”组成\n",
    "- 当然，你也可以通过跟上面一样的处理方式来处理，但是，这种方式对于取值多的字段来说，第一比较繁琐，第二，其实这个赋值方式本身的运行速度很慢\n",
    "- 可以考虑构造一个字典，通过pd.Series.map() 也就是映射的方式来做，方便快捷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3个月', '4个月', '6个月', '7个月', '5个月', '9个月', '8个月', '10个月', '12个月',\n",
       "       '13个月', '18个月', '14个月', '16个月', '11个月', '15个月', '2个月', '17个月',\n",
       "       '1个月'], dtype=object)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.time_span.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1个月': 1, '2个月': 2, '3个月': 3, '4个月': 4, '5个月': 5, '6个月': 6, '7个月': 7, '8个月': 8, '9个月': 9, '10个月': 10, '11个月': 11, '12个月': 12, '13个月': 13, '14个月': 14, '15个月': 15, '16个月': 16, '17个月': 17, '18个月': 18}\n"
     ]
    }
   ],
   "source": [
    "mapping = {}\n",
    "for i in range(1,19):\n",
    "    mapping[str(i) + '个月'] = i\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auth_capital</th>\n",
       "      <th>city</th>\n",
       "      <th>com_class</th>\n",
       "      <th>com_fullname</th>\n",
       "      <th>com_intro</th>\n",
       "      <th>com_logo</th>\n",
       "      <th>com_name</th>\n",
       "      <th>day_per_week</th>\n",
       "      <th>est_date</th>\n",
       "      <th>industry</th>\n",
       "      <th>job_academic</th>\n",
       "      <th>job_deadline</th>\n",
       "      <th>job_links</th>\n",
       "      <th>job_title</th>\n",
       "      <th>num_employee</th>\n",
       "      <th>released_time</th>\n",
       "      <th>tag</th>\n",
       "      <th>time_span</th>\n",
       "      <th>update_time</th>\n",
       "      <th>wage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>235875.0000</td>\n",
       "      <td>北京</td>\n",
       "      <td>公司类型：有限责任公司(台港澳法人独资)</td>\n",
       "      <td>淘宝（中国）软件有限公司</td>\n",
       "      <td>淘宝网是亚太地区较大的网络零售、商圈</td>\n",
       "      <td>https://sxsimg.xiaoyuanzhao.com/FB/BC/FBDB6AC6...</td>\n",
       "      <td>淘宝</td>\n",
       "      <td>4</td>\n",
       "      <td>成立日期：2004-12-07</td>\n",
       "      <td>计算机/互联网</td>\n",
       "      <td>硕士</td>\n",
       "      <td>2018-04-13</td>\n",
       "      <td>https://www.shixiseng.com/intern/inn_g2vpcs8lukcr</td>\n",
       "      <td>【淘宝】算法工程师/算法专家</td>\n",
       "      <td>大型企业</td>\n",
       "      <td>7分钟前</td>\n",
       "      <td>数据挖掘</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-03-21 10:48:06</td>\n",
       "      <td>200-201/天</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27570.9972</td>\n",
       "      <td>上海</td>\n",
       "      <td>公司类型：股份有限公司(上市)</td>\n",
       "      <td>游族网络股份有限公司</td>\n",
       "      <td>全球领先的互动娱乐供应商</td>\n",
       "      <td>https://sxsimg.xiaoyuanzhao.com/BD/6D/BD305709...</td>\n",
       "      <td>游族网络</td>\n",
       "      <td>5</td>\n",
       "      <td>成立日期：1995-09-22</td>\n",
       "      <td>计算机/互联网</td>\n",
       "      <td>本科</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>https://www.shixiseng.com/intern/inn_46watgzrvqsg</td>\n",
       "      <td>大数据挖掘工程师 （2018校园）</td>\n",
       "      <td>中型企业</td>\n",
       "      <td>18分钟前</td>\n",
       "      <td>软件</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-03-21 10:37:22</td>\n",
       "      <td>160-280/天</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>314.5000</td>\n",
       "      <td>广州</td>\n",
       "      <td>公司类型：有限责任公司(台港澳法人独资)</td>\n",
       "      <td>广州网易互动娱乐有限公司</td>\n",
       "      <td>国内中国领先的互联网技术公司，游戏行业领导者。</td>\n",
       "      <td>https://sxsimg.xiaoyuanzhao.com/company_logo/2...</td>\n",
       "      <td>网易游戏</td>\n",
       "      <td>4</td>\n",
       "      <td>成立日期：2002-10-15</td>\n",
       "      <td>互联网</td>\n",
       "      <td>本科</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>https://www.shixiseng.com/intern/inn_wnfrd8o7wly2</td>\n",
       "      <td>数据挖掘研究实习生（AI方向）</td>\n",
       "      <td>大型企业</td>\n",
       "      <td>32分钟前</td>\n",
       "      <td>数据挖掘</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-03-21 10:23:45</td>\n",
       "      <td>130-150/天</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   auth_capital city             com_class  com_fullname  \\\n",
       "0   235875.0000   北京  公司类型：有限责任公司(台港澳法人独资)  淘宝（中国）软件有限公司   \n",
       "1    27570.9972   上海       公司类型：股份有限公司(上市)    游族网络股份有限公司   \n",
       "2      314.5000   广州  公司类型：有限责任公司(台港澳法人独资)  广州网易互动娱乐有限公司   \n",
       "\n",
       "                 com_intro                                           com_logo  \\\n",
       "0       淘宝网是亚太地区较大的网络零售、商圈  https://sxsimg.xiaoyuanzhao.com/FB/BC/FBDB6AC6...   \n",
       "1             全球领先的互动娱乐供应商  https://sxsimg.xiaoyuanzhao.com/BD/6D/BD305709...   \n",
       "2  国内中国领先的互联网技术公司，游戏行业领导者。  https://sxsimg.xiaoyuanzhao.com/company_logo/2...   \n",
       "\n",
       "  com_name day_per_week         est_date industry job_academic job_deadline  \\\n",
       "0       淘宝            4  成立日期：2004-12-07  计算机/互联网           硕士   2018-04-13   \n",
       "1     游族网络            5  成立日期：1995-09-22  计算机/互联网           本科   2020-12-31   \n",
       "2     网易游戏            4  成立日期：2002-10-15      互联网           本科   2018-03-31   \n",
       "\n",
       "                                           job_links          job_title  \\\n",
       "0  https://www.shixiseng.com/intern/inn_g2vpcs8lukcr     【淘宝】算法工程师/算法专家   \n",
       "1  https://www.shixiseng.com/intern/inn_46watgzrvqsg  大数据挖掘工程师 （2018校园）   \n",
       "2  https://www.shixiseng.com/intern/inn_wnfrd8o7wly2    数据挖掘研究实习生（AI方向）   \n",
       "\n",
       "  num_employee released_time   tag  time_span          update_time       wage  \n",
       "0         大型企业          7分钟前  数据挖掘          3  2018-03-21 10:48:06  200-201/天  \n",
       "1         中型企业         18分钟前    软件          4  2018-03-21 10:37:22  160-280/天  \n",
       "2         大型企业         32分钟前  数据挖掘          4  2018-03-21 10:23:45  130-150/天  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean['time_span'] = data['time_span'].map(mapping)#map函数可以用于字典映射\n",
    "data_clean.head(3)#取前三行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.5 “wage”（每天工资）\n",
    "- 通过观察可知，该字段没有缺失值，并且格式全都为：xxx-xxx/天\n",
    "- 可以取一个最低工资，一个最高工资，再求一个平均工资\n",
    "- 这里，可以用之前的pd.Series.apply(function)来做，即定义一个函数提取每条记录中的工资最小和最大值\n",
    "- 不过，更加简便的方法肯定是正则提取啊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368    200-300/天\n",
       "126    200-400/天\n",
       "148    100-200/天\n",
       "745    100-200/天\n",
       "486    200-300/天\n",
       "Name: wage, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['wage'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这一步我估计需要解释一下：\n",
    "- 首先使用正则'([0-9.]+)-([0-9.]+)/天'提取出两列数字（也就是最低和最高工资），设置expand=True返回一个数据框\n",
    "- 由于返回回来的是字符串格式，需要把它们转换为整型（int），所以使用astype('int')\n",
    "- 最后，对每行记录求平均，返回一个Series赋值给data_clean['average_wage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    200.5\n",
       "1    220.0\n",
       "2    140.0\n",
       "3    175.0\n",
       "4    175.0\n",
       "Name: average_wage, dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean['average_wage'] = data['wage'].str.extract('([0-9.]+)-([0-9.]+)/天', expand=True).astype('int').mean(axis = 1)\n",
    "#先用正则求出最小和最大值，转换为int类型，且按照行进行求平均\n",
    "data_clean['average_wage'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 时间数据处理\n",
    "包括“est_date”（公司成立日期）、“job_deadline”（截止时间）、“released_time”（发布时间）、“update_time”（更新时间）等字段  \n",
    "\n",
    "##### 3.3.1 “est_date”（公司成立日期）\n",
    "- 随机抽取发现“est_date”这个字段的格式为：成立日期：xxxx-xx-xx\n",
    "- 因此，直接正则提取，然后把它转换为datetime格式就可以了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "343    成立日期：2007-07-03\n",
       "886    成立日期：2016-08-16\n",
       "622    成立日期：2007-08-13\n",
       "390    成立日期：2012-03-22\n",
       "718    成立日期：2011-07-07\n",
       "Name: est_date, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['est_date'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122   2005-04-11\n",
       "819   2015-08-03\n",
       "859   2000-08-09\n",
       "546          NaT\n",
       "812   2010-11-24\n",
       "Name: est_date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean['est_date'] = pd.to_datetime(data['est_date'].str.extract('成立日期：([0-9-]+)', expand=False))#expand是不作分割的\n",
    "data_clean['est_date'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.2 “job_deadline”（截止时间）\n",
    "- 这个字段很干净，直接类型转换便可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "715    2018-09-30\n",
       "500    2018-04-04\n",
       "777    2018-03-27\n",
       "501    2018-04-04\n",
       "192    2018-04-06\n",
       "Name: job_deadline, dtype: object"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['job_deadline'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean['job_deadline'] = pd.to_datetime(data['job_deadline'])#将string格式转换为日期格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.3 “released_time”（发布时间）\n",
    "- 观察数据发现，该字段1小时内的都以分钟表示、1小时-2天内的都以小时表示、2天-1周内的都以天表示，1周-1个月内的都以周表示，1个月以上的以月表示\n",
    "- 可以考虑清洗成：2天以内是最新的（newest），2天-1周是新的（new），1周-1个月是可以投简历的（acceptable），1个月以上的是旧的（old）\n",
    "- 这个的处理方法很多，我的方法是先把每条记录中的分钟、小时、天、周、月提取出来，再定义一个映射map一下就可以了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303      6天前\n",
       "88     44小时前\n",
       "598      2天前\n",
       "180      1周前\n",
       "493    28小时前\n",
       "Name: released_time, dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['released_time'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "444        newest\n",
       "569           new\n",
       "619           new\n",
       "229           old\n",
       "859    acceptable\n",
       "Name: released_time, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean['released_time'] = data['released_time'].str.extract('[0-9-]+(\\w+)前', expand=False).map(\n",
    "    {'分钟':'newest', '小时':'newest', '天':'new', '周':'acceptable', '月':'old'})\n",
    "    #可以直接把map字典的内容放进去应用，我们主要是正则取单位\n",
    "data_clean['released_time'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.4 “update_time”（更新时间）\n",
    "- 更新时间字段格式很工整，直接转换类型便可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92     2018-03-19 13:54:51\n",
       "233    2018-01-26 11:06:24\n",
       "239    2017-12-29 15:00:46\n",
       "689    2018-03-19 09:29:29\n",
       "800    2018-03-13 10:40:42\n",
       "Name: update_time, dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['update_time'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean['update_time'] = pd.to_datetime(data['update_time'])#转换成日期格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 字符型数据处理\n",
    "包括“city”（城市）、“com_class”（公司类型）、“com_intro（公司简介）”、“job_title”（职位名称）等字段\n",
    "\n",
    "##### 3.4.1 “city”（城市）处理\n",
    "- 乍一看这个字段还挺整洁的，取唯一值看一下发现有些城市还是需要稍微处理一下\n",
    "- 比如说成都有“成都市”和“成都”，珠海有“珠海市”和“珠海”等\n",
    "- 直接赋值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['北京', '上海', '广州', nan, '南京', '深圳', '宁波', '杭州', '西安', '成都', '合肥',\n",
       "       '珠海市', '其他', '重庆', '武汉', '无锡', '天津', '珠海 深圳', '长沙', '厦门', '珠海',\n",
       "       '济南', '香港', '苏州', '上海漕河泾开发区', '晋江', '东莞', '成都市', '大连', '福州', '沈阳'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['city'].unique()#依然是去重合并成数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.loc[data_clean['city'] == '成都市', 'city'] = '成都'#需要替换里面的内容可以用loc，里面就是判断+要更改的字段\n",
    "data_clean.loc[data_clean['city'].isin(['珠海市', '珠海 深圳', '珠海']), 'city'] = '珠海'\n",
    "data_clean.loc[data_clean['city'] == '上海漕河泾开发区', 'city'] = '上海'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 忍不住好奇心，先看一下招聘“机器学习算法”实习生前10的城市\n",
    "- 发现北京遥遥领先、接着是上海、杭州、深圳、广州"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 21271 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 20140 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 19978 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 28023 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 26477 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 24030 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 28145 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 22323 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 24191 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 25104 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 37117 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 21335 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 27494 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 27721 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 35199 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 23433 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 37325 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 24198 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 21271 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 20140 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 19978 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 28023 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 26477 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 24030 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 28145 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 22323 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 24191 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 25104 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 37117 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 21335 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 27494 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 27721 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 35199 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 23433 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 37325 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/chenqiang/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 24198 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clean['city'].value_counts().nlargest(10).plot(kind = 'bar')\n",
    "#取前10的实习生人数的所在城市"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 “com_class”（公司和企业类型）处理\n",
    "- 类型有很多，可以按照组织形式可以分为独资企业、合伙企业、公司制企业，公司制企业又分为有限责任公司和股份有限公司等等\n",
    "- 这里主要把它分为‘股份有限公司（未上市）’、‘股份有限公司（上市）’、‘有限责任公司’、‘外商投资公司’、‘有限合伙企业’、‘国有企业’这6种\n",
    "- 处理方法跟上面币种的处理方法一致"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 首先看看都有哪些公司（或企业）类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['公司类型：有限责任公司(台港澳法人独资)',\n",
       " '公司类型：股份有限公司(上市)',\n",
       " '公司类型：有限责任公司(外国法人独资)',\n",
       " nan,\n",
       " '公司类型：有限责任公司',\n",
       " '公司类型：有限责任公司（法人独资）',\n",
       " '公司类型：其他有限责任公司',\n",
       " ' ',\n",
       " '公司类型：其他股份有限公司(非上市)',\n",
       " '公司类型：有限责任公司(中外合资)',\n",
       " '公司类型：有限责任公司(自然人投资或控股)',\n",
       " '公司类型：有限责任公司(自然人独资)',\n",
       " '公司类型：有限责任公司（自然人投资或控股）',\n",
       " '公司类型：有限责任公司(法人独资)',\n",
       " '公司类型：有限责任公司分公司（自然人独资）',\n",
       " '公司类型：股份有限公司(中外合资、上市)',\n",
       " '公司类型：有限责任公司（台港澳法人独资）',\n",
       " '公司类型：有限责任公司\\n',\n",
       " '公司类型：有限责任公司（自然人独资）',\n",
       " '公司类型：有限责任公司（自然人投资或控股的法人独资）',\n",
       " '公司类型：股份有限公司(非上市、自然人投资或控股)',\n",
       " '公司类型：有限责任公司(台港澳与境内合资)',\n",
       " '公司类型：无',\n",
       " '公司类型：股份有限公司分公司(上市、国有控股)',\n",
       " '公司类型：私营有限责任公司(自然人控股或私营性质企业控股)',\n",
       " '公司类型：全民所有制',\n",
       " '公司类型：有限责任公司（外国法人独资）',\n",
       " '公司类型：股份有限公司(非上市)',\n",
       " '公司类型：股份有限公司(上市、自然人投资或控股)',\n",
       " '公司类型：股份有限公司(台港澳与境内合资、上市)',\n",
       " '公司类型：其他股份有限公司(上市)',\n",
       " '公司类型：有限责任公司分公司（非自然人投资或控股的法人独资）',\n",
       " '公司类型：其他股份有限公司（上市）',\n",
       " '公司类型：有限责任公司（非自然人投资或控股的法人独资）',\n",
       " '公司类型：股份有限公司',\n",
       " '公司类型：非上市股份有限公司',\n",
       " '公司类型：分公司',\n",
       " '公司类型：股份有限公司（上市、自然人投资或控股）',\n",
       " '公司类型：有限合伙',\n",
       " '公司类型：外商投资公司分公司',\n",
       " '公司类型：有限责任公司(台港澳与外国投资者合资)',\n",
       " '公司类型：股份有限公司（非上市）',\n",
       " '公司类型：有限责任公司(外商投资企业法人独资)',\n",
       " '公司类型：上市股份有限公司',\n",
       " '公司类型：股份有限公司(台港澳与境内合资、未上市)',\n",
       " '公司类型：股份有限公司（非上市、自然人投资或控股）',\n",
       " '公司类型：股份有限公司（台港澳与境内合资、未上市）',\n",
       " '公司类型：股份有限公司(中外合资、未上市)']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data['com_class'].unique())#直接以数组的形式呈现和不带list没什么差别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 定义一个函数处理这些类型，利用pd.Series.apply(function)方法\n",
    "- 把处理好的数据保存到data_clean中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_com_type(string):\n",
    "    if string == None:\n",
    "        return np.nan\n",
    "    elif ('非上市' in string) or ('未上市' in string):\n",
    "        return '股份有限公司（未上市）'\n",
    "    elif '股份' in string:\n",
    "        return '股份有限公司（上市）'\n",
    "    elif '责任' in string:\n",
    "        return '有限责任公司'\n",
    "    elif '外商投资' in string:\n",
    "        return '外商投资公司'\n",
    "    elif '有限合伙' in string:\n",
    "        return '有限合伙企业'\n",
    "    elif '全民所有' in string:\n",
    "        return '国有企业'\n",
    "    else:\n",
    "        return np.nan\n",
    "        #跟前面的取利率很像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>com_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>公司类型</td>\n",
       "      <td>有限责任公司（外国法人独资）</td>\n",
       "      <td>有限责任公司</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>公司类型</td>\n",
       "      <td>有限责任公司(自然人投资或控股)</td>\n",
       "      <td>有限责任公司</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>公司类型</td>\n",
       "      <td>有限责任公司(外国法人独资)</td>\n",
       "      <td>有限责任公司</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>公司类型</td>\n",
       "      <td>有限责任公司(台港澳法人独资)</td>\n",
       "      <td>有限责任公司</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0                 1 com_class\n",
       "444  公司类型    有限责任公司（外国法人独资）    有限责任公司\n",
       "799  公司类型  有限责任公司(自然人投资或控股)    有限责任公司\n",
       "65                     None       NaN\n",
       "967  公司类型    有限责任公司(外国法人独资)    有限责任公司\n",
       "2    公司类型   有限责任公司(台港澳法人独资)    有限责任公司"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将空值替换为默认值\n",
    "data['com_class'].fillna('', inplace=True)\n",
    "com_class = data['com_class'].str.split('：', expand = True)#用：分割\n",
    "com_class['com_class'] = com_class[1].apply(get_com_type)#通过get_com_type进行替换\n",
    "com_class.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean['com_class'] = com_class['com_class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- “com_intro”（公司简介）、“job_title”（职位名称）两个字段暂时不处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 “com_logo”（公司logo）、“industry”（行业）也暂时不处理\n",
    "- 更改一下每列的顺序\n",
    "- 再把data_clean保存到本地"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = data_clean.reindex(columns=['com_fullname', 'com_name', 'job_academic', 'job_links', \n",
    "                                         'tag','auth_capital', 'day_per_week', 'num_employee', 'time_span',\n",
    "                                         'average_wage', 'est_date', 'job_deadline', 'released_time',\n",
    "                                         'update_time', 'city', 'com_class', 'com_intro', 'job_title',\n",
    "                                         'com_logo', 'industry'])#修改字段的顺序\n",
    "data_clean.to_csv('/Users/chenqiang/Documents/interesting-python/shixiseng/data_clean.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 数据分析\n",
    "终于可以进入数据分析的阶段。可以利用以上的城市、薪资、学历、行业、公司等相关字段，分析出目前国内公司对机器学习算法实习生的需求状况（仅基于实习僧网站），以及公司的相关情况\n",
    "\n",
    "- 首先，看看清洗完的数据的基本情况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 数据基本情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>com_fullname</th>\n",
       "      <th>com_name</th>\n",
       "      <th>job_academic</th>\n",
       "      <th>job_links</th>\n",
       "      <th>tag</th>\n",
       "      <th>auth_capital</th>\n",
       "      <th>day_per_week</th>\n",
       "      <th>num_employee</th>\n",
       "      <th>time_span</th>\n",
       "      <th>average_wage</th>\n",
       "      <th>est_date</th>\n",
       "      <th>job_deadline</th>\n",
       "      <th>released_time</th>\n",
       "      <th>update_time</th>\n",
       "      <th>city</th>\n",
       "      <th>com_class</th>\n",
       "      <th>com_intro</th>\n",
       "      <th>job_title</th>\n",
       "      <th>com_logo</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>南京贝湾教育科技有限公司</td>\n",
       "      <td>扇贝</td>\n",
       "      <td>不限</td>\n",
       "      <td>https://www.shixiseng.com/intern/inn_r2x1jrgoaxwu</td>\n",
       "      <td>数据挖掘</td>\n",
       "      <td>250.0</td>\n",
       "      <td>4</td>\n",
       "      <td>小型企业</td>\n",
       "      <td>6</td>\n",
       "      <td>225.0</td>\n",
       "      <td>2011-06-24</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>newest</td>\n",
       "      <td>2018-03-21 10:17:03</td>\n",
       "      <td>南京</td>\n",
       "      <td>有限责任公司</td>\n",
       "      <td>中国最大的移动互联网英语学习平台</td>\n",
       "      <td>数据工程师</td>\n",
       "      <td>https://sxsimg.xiaoyuanzhao.com/E0/13/E0E0DCED...</td>\n",
       "      <td>互联网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>广州唯品会信息科技有限公司</td>\n",
       "      <td>唯品会</td>\n",
       "      <td>本科</td>\n",
       "      <td>https://www.shixiseng.com/intern/inn_2st43wvfsa3h</td>\n",
       "      <td>数据挖掘</td>\n",
       "      <td>82450.0</td>\n",
       "      <td>4</td>\n",
       "      <td>大型企业</td>\n",
       "      <td>3</td>\n",
       "      <td>125.0</td>\n",
       "      <td>2008-08-22</td>\n",
       "      <td>2018-03-25</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>2018-02-23 11:17:37</td>\n",
       "      <td>广州</td>\n",
       "      <td>有限责任公司</td>\n",
       "      <td>全球最大的特卖电商、以及中国第三大电商</td>\n",
       "      <td>数据分析实习生（美妆海淘）</td>\n",
       "      <td>https://sxsimg.xiaoyuanzhao.com/4F/BB/4F1A8F2C...</td>\n",
       "      <td>电子商务</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>浙江核新同花顺网络信息股份有限公司</td>\n",
       "      <td>同花顺</td>\n",
       "      <td>硕士</td>\n",
       "      <td>https://www.shixiseng.com/intern/inn_lqvz1fydon8m</td>\n",
       "      <td>算法</td>\n",
       "      <td>53760.0</td>\n",
       "      <td>5</td>\n",
       "      <td>大型企业</td>\n",
       "      <td>4</td>\n",
       "      <td>170.0</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>newest</td>\n",
       "      <td>2018-03-22 09:46:56</td>\n",
       "      <td>杭州</td>\n",
       "      <td>股份有限公司（上市）</td>\n",
       "      <td>中国证券信息服务业的第一家上市公司，互联网金融上市公司</td>\n",
       "      <td>算法实习生</td>\n",
       "      <td>https://sxsimg.xiaoyuanzhao.com/3C/E6/3C3AE769...</td>\n",
       "      <td>互联网金融</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          com_fullname com_name job_academic  \\\n",
       "6         南京贝湾教育科技有限公司       扇贝           不限   \n",
       "223      广州唯品会信息科技有限公司      唯品会           本科   \n",
       "398  浙江核新同花顺网络信息股份有限公司      同花顺           硕士   \n",
       "\n",
       "                                             job_links   tag  auth_capital  \\\n",
       "6    https://www.shixiseng.com/intern/inn_r2x1jrgoaxwu  数据挖掘         250.0   \n",
       "223  https://www.shixiseng.com/intern/inn_2st43wvfsa3h  数据挖掘       82450.0   \n",
       "398  https://www.shixiseng.com/intern/inn_lqvz1fydon8m    算法       53760.0   \n",
       "\n",
       "    day_per_week num_employee  time_span  average_wage   est_date  \\\n",
       "6              4         小型企业          6         225.0 2011-06-24   \n",
       "223            4         大型企业          3         125.0 2008-08-22   \n",
       "398            5         大型企业          4         170.0 2001-08-24   \n",
       "\n",
       "    job_deadline released_time         update_time city   com_class  \\\n",
       "6     2018-04-30        newest 2018-03-21 10:17:03   南京      有限责任公司   \n",
       "223   2018-03-25    acceptable 2018-02-23 11:17:37   广州      有限责任公司   \n",
       "398   2018-06-30        newest 2018-03-22 09:46:56   杭州  股份有限公司（上市）   \n",
       "\n",
       "                       com_intro      job_title  \\\n",
       "6               中国最大的移动互联网英语学习平台          数据工程师   \n",
       "223          全球最大的特卖电商、以及中国第三大电商  数据分析实习生（美妆海淘）   \n",
       "398  中国证券信息服务业的第一家上市公司，互联网金融上市公司          算法实习生   \n",
       "\n",
       "                                              com_logo industry  \n",
       "6    https://sxsimg.xiaoyuanzhao.com/E0/13/E0E0DCED...      互联网  \n",
       "223  https://sxsimg.xiaoyuanzhao.com/4F/BB/4F1A8F2C...     电子商务  \n",
       "398  https://sxsimg.xiaoyuanzhao.com/3C/E6/3C3AE769...    互联网金融  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 878 entries, 0 to 977\n",
      "Data columns (total 20 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   com_fullname   874 non-null    object        \n",
      " 1   com_name       874 non-null    object        \n",
      " 2   job_academic   878 non-null    object        \n",
      " 3   job_links      878 non-null    object        \n",
      " 4   tag            878 non-null    object        \n",
      " 5   auth_capital   782 non-null    float64       \n",
      " 6   day_per_week   878 non-null    object        \n",
      " 7   num_employee   872 non-null    object        \n",
      " 8   time_span      878 non-null    int64         \n",
      " 9   average_wage   878 non-null    float64       \n",
      " 10  est_date       788 non-null    datetime64[ns]\n",
      " 11  job_deadline   878 non-null    datetime64[ns]\n",
      " 12  released_time  878 non-null    object        \n",
      " 13  update_time    878 non-null    datetime64[ns]\n",
      " 14  city           874 non-null    object        \n",
      " 15  com_class      794 non-null    object        \n",
      " 16  com_intro      874 non-null    object        \n",
      " 17  job_title      878 non-null    object        \n",
      " 18  com_logo       874 non-null    object        \n",
      " 19  industry       862 non-null    object        \n",
      "dtypes: datetime64[ns](3), float64(2), int64(1), object(14)\n",
      "memory usage: 144.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很好，数据是想要的样子  \n",
    "  \n",
    "#### 4.2 城市与职位数量\n",
    "- 其实由上面已经知道了，北上广深杭这五个城市毫无疑问地占据了前五的位置，其中北京遥遥领先，有471个职位，占53.89%；上海有164个，占18.76%；北上广深杭这五个城市占了所有的89.93%（将近九成），说明这个职位还是集中在一线城市\n",
    "- 另外值得注意的是，杭州排到了第三，在广州和深圳的前面，说明杭州在这方面的发展还挺好的\n",
    "- 原以为杭州的职位都被阿里系霸占了，结果抽取数据出来一看发现并没有，其中一家叫“非白三维”的公司占了10个职位，这到底是一家什么样的公司？可以去了解一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "北京    471\n",
       "上海    164\n",
       "杭州     55\n",
       "深圳     52\n",
       "广州     44\n",
       "成都     21\n",
       "南京     14\n",
       "武汉      9\n",
       "西安      8\n",
       "重庆      4\n",
       "苏州      4\n",
       "沈阳      4\n",
       "珠海      4\n",
       "合肥      3\n",
       "其他      2\n",
       "Name: city, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city = data_clean['city'].value_counts()\n",
    "city[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/chenqiang/Documents/interesting-python/shixiseng/render.html'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyecharts.charts import Bar      \n",
    "bar = Bar()\n",
    "bar.add_xaxis(city[:15].index)\n",
    "bar.add_yaxis('城市',city[:15].values)\n",
    "# bar.add('', city[:15].index, city[:15].values, mark_point=[\"max\"])\n",
    "\n",
    "bar.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "北京    53.89%\n",
       "上海    18.76%\n",
       "杭州     6.29%\n",
       "深圳     5.95%\n",
       "广州     5.03%\n",
       "成都     2.40%\n",
       "南京     1.60%\n",
       "武汉     1.03%\n",
       "西安     0.92%\n",
       "重庆     0.46%\n",
       "苏州     0.46%\n",
       "沈阳     0.46%\n",
       "珠海     0.46%\n",
       "合肥     0.34%\n",
       "其他     0.23%\n",
       "Name: city, dtype: object"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_pct = (city/city.sum()).map(lambda x: '{:,.2%}'.format(x))\n",
    "city_pct[:15]\n",
    "#求出前15个城市的占比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8993135011441648"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(city/city.sum())[:5].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "非白三维    10\n",
       "光珀       6\n",
       "虹软       5\n",
       "同花顺      4\n",
       "菜鸟网络     3\n",
       "Name: com_name, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.loc[data_clean['city'] == '杭州', 'com_name'].value_counts()[:5]#先判断城市在杭州，并按照公司进行count，求前5个城市"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 再看看这15个个城市中，招聘职位数量前五的公司到底是哪些\n",
    "- 通过定义一个函数topN来实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topN(dataframe, n=5):\n",
    "    counts = dataframe.value_counts()\n",
    "    return counts[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city               \n",
       "北京    百度               21\n",
       "      滴滴出行             19\n",
       "      今日头条             12\n",
       "      京东金融             10\n",
       "      作业帮               9\n",
       "上海    华院数据             10\n",
       "      爱奇艺               8\n",
       "      驭势科技              7\n",
       "      麦穗人工智能            4\n",
       "      名片全能王             4\n",
       "杭州    非白三维             10\n",
       "      光珀                6\n",
       "      虹软                5\n",
       "      同花顺               4\n",
       "      菜鸟网络              3\n",
       "深圳    中科龙智             13\n",
       "      Webot             4\n",
       "      腾讯                3\n",
       "      美图                3\n",
       "      平安科技              3\n",
       "广州    网易游戏              5\n",
       "      探迹                4\n",
       "      欢聚时代（多玩YY）        2\n",
       "      景驰科技              2\n",
       "      汇量科技              2\n",
       "成都    天佑飞天              3\n",
       "      知道创宇              2\n",
       "      西纬科技              1\n",
       "      果小美               1\n",
       "      腾讯                1\n",
       "南京    小黑鱼科技             2\n",
       "      金智信息              2\n",
       "      南京地平线机器人技术        2\n",
       "      扇贝                1\n",
       "      指食针               1\n",
       "武汉    小弦科技              2\n",
       "      武汉安天              1\n",
       "      光庭信息              1\n",
       "      明日数据              1\n",
       "      乐行                1\n",
       "西安    中科微光              3\n",
       "      Wingspan          2\n",
       "      博彦科技              1\n",
       "      绿盟科技              1\n",
       "      西步数据              1\n",
       "重庆    赛迪技术              2\n",
       "      德勤全球交付中心          1\n",
       "      中国信息通信研究院西部分院     1\n",
       "苏州    意能通               2\n",
       "      华兴致远              1\n",
       "      国科康成              1\n",
       "沈阳    东软                2\n",
       "      东软集团              2\n",
       "珠海    网钰科技              1\n",
       "      筑巢科技              1\n",
       "      金山WPS             1\n",
       "      西山居               1\n",
       "合肥    乐职网               3\n",
       "其他    去哪儿网              1\n",
       "      索尼                1\n",
       "Name: com_name, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_clean.groupby('city').com_name.apply(topN).loc[list(city_pct[:15].index)]#取前15城市的数据按照城市进行groupby，取前5的公司，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 薪资\n",
    "\n",
    "##### 4.3.1 平均薪资\n",
    "- 由于\"average_wage\"（薪资）一列的单位是每天，所以可以跟\"day_per_week\"（每周天数）结合起来算每月的工资（以一个月4周算）\n",
    "- 另起一列“salary”（月工资）保存数据\n",
    "- 发现平均实习工资是3645元人民币，应该还是OK的噶？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3644.9407744874716"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean['salary'] = data_clean['average_wage'] * data_clean['day_per_week'] * 4\n",
    "data_clean['salary'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3.2 薪资与城市\n",
    "- 以城市分组，看不同城市平均实习工资怎么样，发现薪资前五名中，北上广深杭只有杭州进入了前五，不过前五中其它四个城市的样本量都太小，数据不具有代表性\n",
    "- 看看职位需求前10的城市，平均实习薪资怎么样，发现杭州是最高的，突破了4000（还算可以的噶？），紧接着是北京3790(弱弱地问一句，够房租不？)，然后是深圳、上海、南京、广州"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city\n",
       "晋江    9000.000000\n",
       "长沙    4500.000000\n",
       "东莞    4150.000000\n",
       "杭州    4139.345455\n",
       "福州    4000.000000\n",
       "北京    3789.927813\n",
       "深圳    3783.538462\n",
       "苏州    3775.000000\n",
       "厦门    3750.000000\n",
       "上海    3579.170732\n",
       "Name: salary, dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_by_city = data_clean.groupby('city')['salary'].mean()#按照城市分组求出每个城市的平均薪资\n",
    "salary_by_city.nlargest(10)#按照降序并求出前10的城市"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "杭州    4139.345455\n",
       "北京    3789.927813\n",
       "深圳    3783.538462\n",
       "上海    3579.170732\n",
       "南京    3420.857143\n",
       "广州    3176.363636\n",
       "成都    2850.000000\n",
       "西安    2317.500000\n",
       "重庆    2222.500000\n",
       "武汉    1912.222222\n",
       "Name: salary, dtype: float64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_city = salary_by_city[city_pct.index[:10]].sort_values(ascending=False)\n",
    "top10_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script>\n",
       "    require.config({\n",
       "        paths: {\n",
       "            'echarts':'https://assets.pyecharts.org/assets/echarts.min', 'vintage':'https://assets.pyecharts.org/assets/themes/vintage'\n",
       "        }\n",
       "    });\n",
       "</script>\n",
       "\n",
       "        <div id=\"21f019426f8848cd9229ad5d5ecb1579\" style=\"width:900px; height:500px;\"></div>\n",
       "\n",
       "<script>\n",
       "        require(['echarts', 'vintage'], function(echarts) {\n",
       "                var chart_21f019426f8848cd9229ad5d5ecb1579 = echarts.init(\n",
       "                    document.getElementById('21f019426f8848cd9229ad5d5ecb1579'), 'vintage', {renderer: 'canvas'});\n",
       "                var option_21f019426f8848cd9229ad5d5ecb1579 = {\n",
       "    \"animation\": true,\n",
       "    \"animationThreshold\": 2000,\n",
       "    \"animationDuration\": 1000,\n",
       "    \"animationEasing\": \"cubicOut\",\n",
       "    \"animationDelay\": 0,\n",
       "    \"animationDurationUpdate\": 300,\n",
       "    \"animationEasingUpdate\": \"cubicOut\",\n",
       "    \"animationDelayUpdate\": 0,\n",
       "    \"series\": [\n",
       "        {\n",
       "            \"type\": \"bar\",\n",
       "            \"legendHoverLink\": true,\n",
       "            \"data\": [\n",
       "                4139.0,\n",
       "                3790.0,\n",
       "                3784.0,\n",
       "                3579.0,\n",
       "                3421.0,\n",
       "                3176.0,\n",
       "                2850.0,\n",
       "                2318.0,\n",
       "                2222.0,\n",
       "                1912.0\n",
       "            ],\n",
       "            \"showBackground\": false,\n",
       "            \"barMinHeight\": 0,\n",
       "            \"barCategoryGap\": \"20%\",\n",
       "            \"barGap\": \"30%\",\n",
       "            \"large\": false,\n",
       "            \"largeThreshold\": 400,\n",
       "            \"seriesLayoutBy\": \"column\",\n",
       "            \"datasetIndex\": 0,\n",
       "            \"clip\": true,\n",
       "            \"zlevel\": 0,\n",
       "            \"z\": 2,\n",
       "            \"label\": {\n",
       "                \"show\": false,\n",
       "                \"position\": \"top\",\n",
       "                \"margin\": 8\n",
       "            },\n",
       "            \"markPoint\": {\n",
       "                \"label\": {\n",
       "                    \"show\": true,\n",
       "                    \"position\": \"inside\",\n",
       "                    \"color\": \"#fff\",\n",
       "                    \"margin\": 8\n",
       "                },\n",
       "                \"data\": [\n",
       "                    {\n",
       "                        \"name\": \"\\u6700\\u5927\\u503c\",\n",
       "                        \"type\": \"max\"\n",
       "                    }\n",
       "                ]\n",
       "            }\n",
       "        }\n",
       "    ],\n",
       "    \"legend\": [\n",
       "        {\n",
       "            \"data\": [\n",
       "                \"\"\n",
       "            ],\n",
       "            \"selected\": {\n",
       "                \"\": true\n",
       "            },\n",
       "            \"show\": true,\n",
       "            \"padding\": 5,\n",
       "            \"itemGap\": 10,\n",
       "            \"itemWidth\": 25,\n",
       "            \"itemHeight\": 14\n",
       "        }\n",
       "    ],\n",
       "    \"tooltip\": {\n",
       "        \"show\": true,\n",
       "        \"trigger\": \"item\",\n",
       "        \"triggerOn\": \"mousemove|click\",\n",
       "        \"axisPointer\": {\n",
       "            \"type\": \"line\"\n",
       "        },\n",
       "        \"showContent\": true,\n",
       "        \"alwaysShowContent\": false,\n",
       "        \"showDelay\": 0,\n",
       "        \"hideDelay\": 100,\n",
       "        \"textStyle\": {\n",
       "            \"fontSize\": 14\n",
       "        },\n",
       "        \"borderWidth\": 0,\n",
       "        \"padding\": 5\n",
       "    },\n",
       "    \"xAxis\": [\n",
       "        {\n",
       "            \"show\": true,\n",
       "            \"scale\": false,\n",
       "            \"nameLocation\": \"end\",\n",
       "            \"nameGap\": 15,\n",
       "            \"gridIndex\": 0,\n",
       "            \"inverse\": false,\n",
       "            \"offset\": 0,\n",
       "            \"splitNumber\": 5,\n",
       "            \"minInterval\": 0,\n",
       "            \"splitLine\": {\n",
       "                \"show\": false,\n",
       "                \"lineStyle\": {\n",
       "                    \"show\": true,\n",
       "                    \"width\": 1,\n",
       "                    \"opacity\": 1,\n",
       "                    \"curveness\": 0,\n",
       "                    \"type\": \"solid\"\n",
       "                }\n",
       "            },\n",
       "            \"data\": [\n",
       "                \"\\u676d\\u5dde\",\n",
       "                \"\\u5317\\u4eac\",\n",
       "                \"\\u6df1\\u5733\",\n",
       "                \"\\u4e0a\\u6d77\",\n",
       "                \"\\u5357\\u4eac\",\n",
       "                \"\\u5e7f\\u5dde\",\n",
       "                \"\\u6210\\u90fd\",\n",
       "                \"\\u897f\\u5b89\",\n",
       "                \"\\u91cd\\u5e86\",\n",
       "                \"\\u6b66\\u6c49\"\n",
       "            ]\n",
       "        }\n",
       "    ],\n",
       "    \"yAxis\": [\n",
       "        {\n",
       "            \"name\": \"\\u5143/\\u6708\",\n",
       "            \"show\": true,\n",
       "            \"scale\": false,\n",
       "            \"nameLocation\": \"end\",\n",
       "            \"nameGap\": 15,\n",
       "            \"gridIndex\": 0,\n",
       "            \"inverse\": false,\n",
       "            \"offset\": 0,\n",
       "            \"splitNumber\": 5,\n",
       "            \"minInterval\": 0,\n",
       "            \"splitLine\": {\n",
       "                \"show\": false,\n",
       "                \"lineStyle\": {\n",
       "                    \"show\": true,\n",
       "                    \"width\": 1,\n",
       "                    \"opacity\": 1,\n",
       "                    \"curveness\": 0,\n",
       "                    \"type\": \"solid\"\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    ],\n",
       "    \"title\": [\n",
       "        {\n",
       "            \"text\": \"\\u5317\\u4e0a\\u5e7f\\u6df1\\u676d\\u7b49\\u57ce\\u5e02\\u5e73\\u5747\\u5b9e\\u4e60\\u5de5\\u8d44\",\n",
       "            \"padding\": 5,\n",
       "            \"itemGap\": 10\n",
       "        }\n",
       "    ]\n",
       "};\n",
       "                chart_21f019426f8848cd9229ad5d5ecb1579.setOption(option_21f019426f8848cd9229ad5d5ecb1579);\n",
       "        });\n",
       "    </script>\n"
      ],
      "text/plain": [
       "<pyecharts.render.display.HTML at 0x7f8c509a3a30>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bar = pyecharts.Bar('北上广深杭等城市平均实习工资')\n",
    "# bar.add('', top10_city.index, np.round(top10_city.values, 0), mark_point=[\"max\"], is_convert=True)\n",
    "# bar\n",
    "\n",
    "\n",
    "import pyecharts.options as opts\n",
    "from pyecharts.globals import ThemeType\n",
    "from pyecharts.charts import Bar\n",
    "\n",
    "bar = Bar(init_opts=opts.InitOpts(theme=ThemeType.VINTAGE))\n",
    "bar.add_xaxis(top10_city.index.tolist())\n",
    "bar.add_yaxis('', np.round(top10_city.values, 0).tolist(),\n",
    "              label_opts=opts.LabelOpts(is_show=False),\n",
    "              markpoint_opts=opts.MarkPointOpts(\n",
    "                  data=[opts.MarkPointItem(type_='max', name='最大值')]\n",
    "              ))\n",
    "bar.set_global_opts(title_opts=opts.TitleOpts(title='北上广深杭等城市平均实习工资'),\n",
    "                    yaxis_opts=opts.AxisOpts(name='元/月'))\n",
    "bar.render_notebook()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 再看看这些城市实习薪资的分布怎么样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "No loop matching the specified signature and casting was found for ufunc add",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0n/6mryfm8x06gfzddk4dympfg80000gn/T/ipykernel_7432/899227489.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtop10_city_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'city'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop10_city\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviolinplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'salary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'city'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop10_city_box\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'width'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'quartile'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/seaborn/_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             )\n\u001b[1;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mviolinplot\u001b[0;34m(x, y, hue, data, order, hue_order, bw, cut, scale, scale_hue, gridsize, width, inner, split, dodge, orient, linewidth, color, palette, saturation, ax, **kwargs)\u001b[0m\n\u001b[1;32m   2398\u001b[0m ):\n\u001b[1;32m   2399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2400\u001b[0;31m     plotter = _ViolinPlotter(x, y, hue, data, order, hue_order,\n\u001b[0m\u001b[1;32m   2401\u001b[0m                              \u001b[0mbw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_hue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgridsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2402\u001b[0m                              \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdodge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, hue, data, order, hue_order, bw, cut, scale, scale_hue, gridsize, width, inner, split, dodge, orient, linewidth, color, palette, saturation)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestablish_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestablish_colors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_densities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_hue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgridsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgridsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgridsize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mestimate_densities\u001b[0;34m(self, bw, cut, scale, scale_hue, gridsize)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m                 \u001b[0;31m# Fit the KDE and get the used bandwidth size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m                 \u001b[0mkde\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbw_used\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_kde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkde_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;31m# Determine the support grid and get the density over it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mfit_kde\u001b[0;34m(self, x, bw)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_kde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0;34m\"\"\"Estimate a KDE for a vector of data with flexible bandwidth.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mkde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_kde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;31m# Extract the numeric bandwidth from the KDE object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, bw_method, weights)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_neff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weights\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_bandwidth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36mset_bandwidth\u001b[0;34m(self, bw_method)\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_covariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compute_covariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36m_compute_covariance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;31m# Cache covariance and inverse covariance of the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_data_inv_cov'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             self._data_covariance = atleast_2d(cov(self.dataset, rowvar=1,\n\u001b[0m\u001b[1;32m    564\u001b[0m                                                \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                                                aweights=self.weights))\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcov\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[1;32m   2467\u001b[0m             \u001b[0mw\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0maweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2469\u001b[0;31m     \u001b[0mavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2470\u001b[0m     \u001b[0mw_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_sum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36maverage\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mwgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mscl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscl\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             raise ZeroDivisionError(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     45\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     46\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[0;31mTypeError\u001b[0m: No loop matching the specified signature and casting was found for ufunc add"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "top10_city_box = data_clean.loc[data_clean['city'].isin(top10_city.index), :]\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.violinplot(x='salary', y='city', data=top10_city_box, scale='width', inner='quartile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 学历\n",
    "\n",
    "##### 4.4.1 数据挖掘、机器学习算法的学历要求\n",
    "- 先看看总体来说，需要什么学历的最多，发现需求的本科生数量是最多的，约占50%，紧接着是硕士，约占30%，博士是最少的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "本科    435\n",
       "硕士    267\n",
       "不限    160\n",
       "大专     12\n",
       "博士      4\n",
       "Name: job_academic, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_academic = data_clean['job_academic'].value_counts()\n",
    "job_academic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script>\n",
       "    require.config({\n",
       "        paths: {\n",
       "            'echarts':'https://assets.pyecharts.org/assets/echarts.min'\n",
       "        }\n",
       "    });\n",
       "</script>\n",
       "\n",
       "        <div id=\"83f78e62cbb44f2dac783cd39beff501\" style=\"width:900px; height:500px;\"></div>\n",
       "\n",
       "<script>\n",
       "        require(['echarts'], function(echarts) {\n",
       "                var chart_83f78e62cbb44f2dac783cd39beff501 = echarts.init(\n",
       "                    document.getElementById('83f78e62cbb44f2dac783cd39beff501'), 'white', {renderer: 'canvas'});\n",
       "                var option_83f78e62cbb44f2dac783cd39beff501 = {\n",
       "    \"animation\": true,\n",
       "    \"animationThreshold\": 2000,\n",
       "    \"animationDuration\": 1000,\n",
       "    \"animationEasing\": \"cubicOut\",\n",
       "    \"animationDelay\": 0,\n",
       "    \"animationDurationUpdate\": 300,\n",
       "    \"animationEasingUpdate\": \"cubicOut\",\n",
       "    \"animationDelayUpdate\": 0,\n",
       "    \"color\": [\n",
       "        \"#c23531\",\n",
       "        \"#2f4554\",\n",
       "        \"#61a0a8\",\n",
       "        \"#d48265\",\n",
       "        \"#749f83\",\n",
       "        \"#ca8622\",\n",
       "        \"#bda29a\",\n",
       "        \"#6e7074\",\n",
       "        \"#546570\",\n",
       "        \"#c4ccd3\",\n",
       "        \"#f05b72\",\n",
       "        \"#ef5b9c\",\n",
       "        \"#f47920\",\n",
       "        \"#905a3d\",\n",
       "        \"#fab27b\",\n",
       "        \"#2a5caa\",\n",
       "        \"#444693\",\n",
       "        \"#726930\",\n",
       "        \"#b2d235\",\n",
       "        \"#6d8346\",\n",
       "        \"#ac6767\",\n",
       "        \"#1d953f\",\n",
       "        \"#6950a1\",\n",
       "        \"#918597\"\n",
       "    ],\n",
       "    \"series\": [\n",
       "        {\n",
       "            \"type\": \"pie\",\n",
       "            \"clockwise\": true,\n",
       "            \"data\": [\n",
       "                {\n",
       "                    \"name\": \"\\u672c\\u79d1\",\n",
       "                    \"value\": 435\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7855\\u58eb\",\n",
       "                    \"value\": 267\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e0d\\u9650\",\n",
       "                    \"value\": 160\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5927\\u4e13\",\n",
       "                    \"value\": 12\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u535a\\u58eb\",\n",
       "                    \"value\": 4\n",
       "                }\n",
       "            ],\n",
       "            \"radius\": [\n",
       "                \"0%\",\n",
       "                \"75%\"\n",
       "            ],\n",
       "            \"center\": [\n",
       "                \"50%\",\n",
       "                \"50%\"\n",
       "            ],\n",
       "            \"label\": {\n",
       "                \"show\": true,\n",
       "                \"position\": \"top\",\n",
       "                \"margin\": 8\n",
       "            }\n",
       "        }\n",
       "    ],\n",
       "    \"legend\": [\n",
       "        {\n",
       "            \"data\": [\n",
       "                \"\\u672c\\u79d1\",\n",
       "                \"\\u7855\\u58eb\",\n",
       "                \"\\u4e0d\\u9650\",\n",
       "                \"\\u5927\\u4e13\",\n",
       "                \"\\u535a\\u58eb\"\n",
       "            ],\n",
       "            \"selected\": {},\n",
       "            \"show\": true,\n",
       "            \"padding\": 5,\n",
       "            \"itemGap\": 10,\n",
       "            \"itemWidth\": 25,\n",
       "            \"itemHeight\": 14\n",
       "        }\n",
       "    ],\n",
       "    \"tooltip\": {\n",
       "        \"show\": true,\n",
       "        \"trigger\": \"item\",\n",
       "        \"triggerOn\": \"mousemove|click\",\n",
       "        \"axisPointer\": {\n",
       "            \"type\": \"line\"\n",
       "        },\n",
       "        \"showContent\": true,\n",
       "        \"alwaysShowContent\": false,\n",
       "        \"showDelay\": 0,\n",
       "        \"hideDelay\": 100,\n",
       "        \"textStyle\": {\n",
       "            \"fontSize\": 14\n",
       "        },\n",
       "        \"borderWidth\": 0,\n",
       "        \"padding\": 5\n",
       "    },\n",
       "    \"title\": [\n",
       "        {\n",
       "            \"text\": \"\\u5b66\\u5386\\u8981\\u6c42\",\n",
       "            \"padding\": 5,\n",
       "            \"itemGap\": 10\n",
       "        }\n",
       "    ]\n",
       "};\n",
       "                chart_83f78e62cbb44f2dac783cd39beff501.setOption(option_83f78e62cbb44f2dac783cd39beff501);\n",
       "        });\n",
       "    </script>\n"
      ],
      "text/plain": [
       "<pyecharts.render.display.HTML at 0x7f8c51556070>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pie = pyecharts.Pie(\"学历要求\")\n",
    "# pie.add('', job_academic.index, job_academic.values)\n",
    "# pie\n",
    "\n",
    "import pyecharts.options as opts\n",
    "from pyecharts.charts import Pie\n",
    "job_academic = data_clean['job_academic'].value_counts()\n",
    "job_academic\n",
    "pie = Pie()\n",
    "pie.set_global_opts(title_opts=opts.TitleOpts(title=\"学历要求\"))\n",
    "data = [(k,v) for k,v in job_academic.items()]\n",
    "pie.add(\"\", data)\n",
    "pie.render_notebook()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4.2 学历与薪资\n",
    "- 再看看实习薪资和学历有什么关系。发现基本上是正相关的关系，博士最高，接着是硕士、本科、大专\n",
    "- 但是，本科和硕士的实习工资差别不大\n",
    "- 总体看起来实习工资都偏低一些（不知道大家的实习工资是多少呢？），就算是博士也不太高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.groupby(['job_academic'])['salary'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"job_academic\", y=\"salary\", data=data_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 行业\n",
    "- 有一个好奇是，在现在的各行各业中，哪些行业对数据挖掘、机器学习算法的实习生需求更多，还有哪些行业现在也正在应用机器学习算法\n",
    "- “industry”字段是前面还未处理的，先看看数据长什么样子，发现同一条记录可能对应着一个或者多个行业，格式为xxx/xxx或者xxx,xxx，或者xxx，xxx等\n",
    "- 字段存在一定的缺失值\n",
    "- 考虑把字段按照/,，分割，行业名称每出现一次，做一次记录，比如“计算机/互联网,金融”，既属于“计算机”行业、又属于“互联网”行业，也属于“金融行业”，因此这3个行业的记录加1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean['industry'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry = data_clean.industry.str.split('/|,|，', expand = True)#进行分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里需要解释一下：\n",
    "- 首先把上面split好的industry应用pandas的顶级方法value_counts，计算出每列不同行业的记录数\n",
    "- 然后把这几列的数据加起来，得到总数\n",
    "- 再取top15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_top15 = industry.apply(pd.value_counts).sum(axis = 1).nlargest(15)#求出每组的记录数，并求出前15名的种类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = pyecharts.Bar('行业与职位数量')\n",
    "bar.add('', industry_top15.index, industry_top15.values, \n",
    "        mark_point=[\"max\",\"min\",\"average\"], xaxis_rotate=45)\n",
    "bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由上可知：\n",
    "- 互联网和计算机行业对于这方面的实习生需求是最多的（这是当然）\n",
    "- 金融、通信、电子行业对于这方面的实习生需求在前五名，说明数据挖掘、机器学习算法在这些行业也得到了比较好的应用\n",
    "- 另外，一些传统行业比如说机械、制造，也对这方面的实习生有些许需求，说明传统行业也开始关注和探索新的技术\n",
    "- 医药行业和教育培训行业也对此有些许需求；其实医药行业对机器学习算法的探索已经很多了，教育培训呢，估计是机器学习最近几年的蓬勃发展也带动了教育培训的发展吧"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 公司\n",
    "有很多跟公司相关的字段，很好奇哪些公司现在招的实习生职位数量最多、公司规模如何、这些公司都是什么时候成立的、是不是最近几年新成立的公司占的比例比较大、哪些公司给的实习薪资高一些、哪些公司比较看重学历\n",
    "  \n",
    "##### 4.5.1 公司与职位数量、平均实习月薪\n",
    "- 看看招聘职位数量前15名的公司都有哪些。发现了很多耳熟能详的大公司，比如说百度、滴滴、爱奇艺、头条、京东等\n",
    "- 还有一些比较陌生的，比如中科龙智、华院数据、非白三维、恒润科技、驭势科技、Rokid A-Lab等，这些公司都值得去了解一下\n",
    "- 这些公司中，今日头条的平均实习月薪最高，6400.5元，非白三维这家公司的实习月薪也不错，5150元，比某度好多了哈哈哈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.groupby('com_name').salary.agg(['count', 'mean']).sort_values(by='count', ascending = False)[:15]\n",
    "#按照公司分组，求每个公司的职位以及平均工资，然后按照职位数量排序，取前15名"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5.2 公司规模与职位数量\n",
    "- 数据挖掘、机器学习的实习生的需求，是否是以大型企业为主导呢？\n",
    "- 发现并不是的，这方面的需求是以小中大型企业向下递减的，也间接说明了这个行业迅速发展的同时催生了很多中小企业吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean['num_employee'].value_counts()#求出每个公司大小的记录数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5.3 公司规模与实习月薪\n",
    "- 我猜应该是大公司实习月薪高，小公司实习月薪低吧\n",
    "- 发现：我还是太天真了，结果刚好相反，小公司给的高，大公司给的低\n",
    "- 仔细想想好像也不无道理，大公司靠自己的名气吸引实习生，小公司没有名气，只能靠给更多的钱来吸引实习生了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.groupby('num_employee')['salary'].mean()#按照公司规模分组求工资的平均水平"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5.4 公司实习期长度\n",
    "- 发现大多数公司要求的是实习3个月和6个月，基本上都是实习三个月起\n",
    "- 平均实习期长度是五个半月"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean['time_span'].value_counts()#按照实习时长求记录数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean['time_span'].mean()#求工作时长的平均数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5.5 企业成立时间\n",
    "刚好可以用企业成立时间验证一下猜想，也就是最近这个行业是否得到了迅速的成长，迅速成长的过程中，是否又催生了一大批的中小企业\n",
    "- 首先，因为计算的是企业的数量而不是职位的数量，所以要先drop掉重复的企业\n",
    "- 接着，把之前清理好的成立时间数据，再清理一下，以年做单位\n",
    "- 然后，以年分组计算数量，便得到每年新成立的公司数量\n",
    "- 发现：从2013年开始，公司呈现爆发式增长"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_date = data_clean.drop_duplicates(subset='com_name')#按照公司名称干掉重复的企业"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "est_date['est_year'] = pd.DatetimeIndex(est_date['est_date']).year\n",
    "num_com_by_year = est_date.groupby('est_year')['com_name'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = pyecharts.Line(\"每年新成立的公司数量变化\")\n",
    "line.add(\"\", num_com_by_year.index, num_com_by_year.values, mark_line=[\"max\", \"average\"])\n",
    "line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那新成立的企业中，企业规模怎么样？\n",
    "- 把数据以企业规模和成立年份分组计数\n",
    "- 发现2013年之后的爆发式增长中，主要以中小型企业为主（当然，这里也可以使用注册资本字段来做）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scale_VS_year = est_date.groupby(['num_employee', 'est_year'])['com_name'].count()\n",
    "scale_VS_year_s = scale_VS_year['小型企业'].reindex(num_com_by_year.index, fill_value=0)\n",
    "scale_VS_year_m = scale_VS_year['中型企业'].reindex(num_com_by_year.index, fill_value=0)\n",
    "scale_VS_year_l = scale_VS_year['大型企业'].reindex(num_com_by_year.index, fill_value=0)\n",
    "\n",
    "line = pyecharts.Line(\"新成立的企业与规模\")\n",
    "line.add(\"小型企业\", scale_VS_year_s.index, scale_VS_year_s.values, is_label_show=True)\n",
    "line.add(\"中型企业\", scale_VS_year_m.index, scale_VS_year_m.values, is_label_show=True)\n",
    "line.add(\"大型企业\", scale_VS_year_l.index, scale_VS_year_l.values, is_label_show=True)\n",
    "line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 给小E挑选实习公司\n",
    "从以上的数据分析我们可以知道：\n",
    "1. 数据挖掘、机器学习算法岗位实习生的招聘，主要集中在“北上广深杭”这5个大城市\n",
    "2. 实习生的平均薪资为3644元人民币，“北上广深杭”这五个城市中，杭州的薪资最高，再者是北京、深圳\n",
    "3. 实习生学习以本科和硕士居多，并且这两者在实习薪资待遇上并没有太大的差别\n",
    "4. 互联网和计算机行业对于数据挖掘、机器学习算法岗位实习生需求是最多的，再者是金融、通信、电子行业\n",
    "5. 百度、滴滴、爱奇艺、头条、京东等大公司对该岗位的需求很多，另外还有中科龙智、华院数据、非白三维、恒润科技、驭势科技、Rokid A-Lab这些比较陌生的公司，对于该岗位的需求很多（应该是公司这方面的业务出于快速发展阶段）\n",
    "6. 大公司的实习薪资较少，小公司的薪资较多，不过差别不大\n",
    "7. 实习期以3个月或者6个月为主\n",
    "8. 从2013年开始，该行业的迅速发展催生了很多新的公司，主要以中小企业为主\n",
    "\n",
    "  \n",
    "这便是实习僧网站上，国内“机器学习算法实习生”岗位的一些基本情况。下面还有一个任务就是，给小E挑选一些符合小E的公司，供小E投简历。\n",
    "小E的相关信息：\n",
    "- 深圳人\n",
    "- 硕士在读\n",
    "- 只能实习3个月\n",
    "- 薪资高于深圳平均实习薪资\n",
    "- 要求是最新发布的职位\n",
    "\n",
    "  \n",
    "最后剩下......鹅厂......\n",
    "那就鹅厂吧，把鹅厂的这3条记录提取出来，完事儿！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_data = data_clean.loc[(data_clean['city'] == '深圳') & \n",
    "               (data_clean['job_academic'] != '博士') & \n",
    "               (data_clean['time_span'].isin([1,2,3])) & \n",
    "               (data_clean['salary'] > 3784) & \n",
    "               (data_clean['released_time'] == 'newest'), :]#loc后面就是判断语句\n",
    "E_data['com_name'].unique()#去重合并成数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[E_data.index, ['job_title', 'job_links']]#找出岗位名称和岗位链接"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. logo拼图\n",
    "最后，一个小乐趣：数据中有\"com_logo\"（公司logo）的链接地址，可以下载回来然后做个公司logo拼图\n",
    "1. 首先，需要先按照“com_logo”字段的链接，把所有的logo图片下载回来\n",
    "- 先选取“com_logo”和“com_name”两列数据，按照“com_name”列去重，去缺失值\n",
    "- 由于我们要使用“com_name”字段来命名爬取回来的logo，而其有些记录带有\"/\"符号，跟路径的符号会起冲突，所以先把这个符号用“-”替换掉\n",
    "- 接着使用requests库批量下载这些logo图片，保存到“logo”文件夹中(注意：保存logo的这个目标文件夹需要自己先新建)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "data_logo = data_clean[['com_logo', 'com_name']]\n",
    "data_logo.drop_duplicates(subset='com_name', inplace=True)\n",
    "data_logo.dropna(inplace=True)\n",
    "data_logo['com_name'] = data_logo['com_name'].str.replace('/', '-')\n",
    "com_logo = list(data_logo['com_logo'])\n",
    "com_name = list(data_logo['com_name'])\n",
    "\n",
    "path_list = []\n",
    "num_logo = 0\n",
    "os.mkdir('/Users/apple/Desktop/shixiseng/logo')\n",
    "for logo_index in range(len(com_logo)):\n",
    "    try:\n",
    "        response = requests.get(com_logo[logo_index])\n",
    "        suffix = com_logo[logo_index].split('.')[-1]\n",
    "        path = '/Users/apple/Desktop/shixiseng/logo/{}.{}'.format(com_name[logo_index], suffix)\n",
    "        path_list.append(path)\n",
    "        with open(path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        num_logo += 1\n",
    "    except:\n",
    "        print('Failed downloading logo of', com_name[logo_index])\n",
    "print('Successfully downloaded ', str(num_logo), 'logos!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面使用PIL做一个logo拼图，由于爬取回来有459个logo，为了美观，这里只选取了位于前面的400个logo，长宽各20个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = y = 0\n",
    "line = 20\n",
    "NewImage = Image.new('RGB', (128*line, 128*line))\n",
    "for item in path_list:\n",
    "    try:\n",
    "        img = Image.open(item)\n",
    "        img = img.resize((128, 128), Image.ANTIALIAS)\n",
    "        NewImage.paste(img, (x * 128, y * 128))\n",
    "        x += 1\n",
    "    except IOError:\n",
    "        print(\"第%d行,%d列文件读取失败！IOError:%s\" % (y, x, item))\n",
    "        x -= 1\n",
    "    if x == line:\n",
    "        x = 0\n",
    "        y += 1\n",
    "    if (x + line * y) == line * line:\n",
    "        break\n",
    "NewImage.save(\"/Users/apple/Desktop/shixiseng/logo.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完事儿，回家，吃饭！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 总结一下\n",
    "- 首先，由于这篇文章的目的是给小E分析数据挖掘、机器学习算法实习生的需求情况，并且只爬了“实习僧”这一个网站，所以数据量比较小\n",
    "- 不过，数据的清洗和分析的套路还是差不多的\n",
    "- 由于前段时间了解到pyecharts这个画图神器，所以想在这里用一下。pyecharts画出来的图确实漂亮，不过总体感觉现在它跟pandas还是结合地不够好，用起来稍微有点繁琐，希望后面会越来越好越来越方便吧\n",
    "- 吃饭了，溜了溜了"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21ee8af2579a8192c5b3880b850b5f93eed7daf2eb79d75b82c39de695db0d6e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
